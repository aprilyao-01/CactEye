{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b93eb5",
   "metadata": {},
   "source": [
    "# What's this notebook used for\n",
    "This notebook is the classifier. First upload your image by changing the image filepath, tran_dir is for images be used to train the module, validation_dir is for images to calidate, test_dir is images used for this classifier to test.\n",
    "\n",
    "In our project we used the blender rendered synthetc images for training and validation, used real world images to test, this classifier will output which type of cacti is your test image if you have similer image for train and valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5f2e9",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "First make sure TensorFlow and TensorFlow Hub are set up and import all of the modules we need.\n",
    "### Action Required\n",
    "- If you have not already installed tensorflow, tensorflow-hub, and matplotlib in your environment, do so here by uncommenting the appropriate lines\n",
    "- If you have a CUDA GPU and wan to use Tensorflow GPU, use the \"pip install tensorflow-gpu\" line, otherwise use \"pip install tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1090c",
   "metadata": {},
   "source": [
    "## Load Training, Validation, and Test Datasets\n",
    "We want to load our training, validation, and test images into ImageDataGenerators, which will be used to train/validate our TensorFlow model.\n",
    "\n",
    "### Action Required\n",
    "- Update the **train_dir**, **validation_dir**, & **test_dir** directory paths below to match where you've saved your datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the IMAGE_SHAPE, train_dir, validation_dir, and test_dir\n",
    "IMAGE_SHAPE = (224, 224)      # the size of blender render image, for this model, the input size is fixed to 224x224 pixels\n",
    "\n",
    "#change the path to your image folder\n",
    "train_dir      = '/Users/i52/Downloads/tmp/train'    # the directry of the output images\n",
    "validation_dir = '/Users/i52/Downloads/tmp/val'\n",
    "test_dir       = '/Users/i52/Downloads/tmp/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training image generator and data generator\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "train_data_gen = train_image_generator.flow_from_directory(directory=train_dir, shuffle=True, target_size=IMAGE_SHAPE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de02795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation image generator and data generator\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = validation_image_generator.flow_from_directory(directory=validation_dir, shuffle=True, target_size=IMAGE_SHAPE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3536fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test image generator and data generator\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = test_image_generator.flow_from_directory(directory=test_dir, shuffle=True, target_size=IMAGE_SHAPE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011dda3",
   "metadata": {},
   "source": [
    "## Display Sample Images\n",
    "Now we'll display a few sample images from the Training and Validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3451ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_samples(data_gen, title):\n",
    "    # Make a lookup dictionary for class indexes\n",
    "    classes = dict()\n",
    "    for key, val in data_gen.class_indices.items():\n",
    "        classes[val] = key\n",
    "\n",
    "    # Get sample images and labels\n",
    "    sample_images, sample_labels = next(data_gen)\n",
    "\n",
    "    # Plot the images and labels\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for n in range(5):\n",
    "        plt.subplot(1,5,n+1)\n",
    "        plt.imshow(sample_images[n])\n",
    "        plt.title(classes[np.argmax(sample_labels[n])])\n",
    "        plt.axis('off')\n",
    "    _ = plt.suptitle(title)\n",
    "\n",
    "display_samples(train_data_gen, 'Sample Training Images')\n",
    "display_samples(validation_data_gen, 'Sample Validation Images')\n",
    "display_samples(test_data_gen, 'Sample Test Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f3083",
   "metadata": {},
   "source": [
    "## Creating the TensorFlow Model\n",
    "Now we'll create a new TensorFlow model based on the \"imagenet/mobilenet_v2_100_224/feature_vector\". This is a pre-trained model, but it has never been trained on 3D letters before, so we'll be retraining it for our purposes further below.\n",
    "\n",
    "Description: \"Feature vectors of images with MobileNet V2 (depth multiplier 1.00) trained on ImageNet (ILSVRC-2012-CLS).\"\n",
    "\n",
    "Source: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow model for classifying images\n",
    "\n",
    "# a list of the different class in index from that were in the training dataset -> how many class we have\n",
    "num_classes = len(train_data_gen.class_indices)\n",
    "\n",
    "# using the pre-trained model as base, trainable=False -> donot retrain the model\n",
    "#IMAGE_SHAPE+(3,) -> (224,224,3)  (IS,IS,3) -> 3: red green blue channel-> 3 channels of 224 pixels by 224 pixels \n",
    "# softmix -> the deep learing methord\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "                   trainable=False, input_shape=IMAGE_SHAPE+(3,)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Print out the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aace82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db7eab",
   "metadata": {},
   "source": [
    "## Training\n",
    "Train our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the train & val steps per epoch\n",
    "train_steps_per_epoch = np.ceil(train_data_gen.samples/train_data_gen.batch_size)\n",
    "val_steps_per_epoch = np.ceil(validation_data_gen.samples/validation_data_gen.batch_size)\n",
    "\n",
    "# Train the model\n",
    "epochs = 3\n",
    "history = model.fit(train_data_gen, epochs=epochs,\n",
    "                    steps_per_epoch=train_steps_per_epoch,\n",
    "                    validation_data=validation_data_gen,\n",
    "                    validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32153c74",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Now that our model is trained, let's run some of our test images through it.\n",
    "### Evaluate\n",
    "The first thing we'll do is evaluate the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data_gen)\n",
    "print(f'Loss: {results[0]:.4f}')\n",
    "print(f'Accuracy: {results[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c0bff",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "Now we will make predictions on the test dataset and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a lookup numpy array for class names\n",
    "class_names = np.empty([len(test_data_gen.class_indices)], dtype=object, order='C')\n",
    "for key, val in test_data_gen.class_indices.items():\n",
    "    class_names[val] = key\n",
    "\n",
    "# Get a test batch of images and labels\n",
    "test_data_gen.reset()\n",
    "image_batch, label_batch = next(test_data_gen)\n",
    "\n",
    "# Predict the class of each image using our model\n",
    "predicted_batch = model.predict(image_batch)        #send the image to nural network \n",
    "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]\n",
    "label_id = np.argmax(label_batch, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599de83",
   "metadata": {},
   "source": [
    "## Show Predictions\n",
    "Now we'll display predictions for our first 30 test images. If training worked properly, most of them should be correct, and the ones that fail should be fairly challenging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123ab8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "for n in range(min(30, len(image_batch))):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(image_batch[n])\n",
    "    color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
    "    t = f'{predicted_batch[n][predicted_id[n]]:.2f} {predicted_label_batch[n].title()}'\n",
    "    plt.title(t, color=color)\n",
    "    plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
